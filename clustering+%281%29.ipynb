{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datalab.bigquery as bq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql --module logspreview1\n",
    "SELECT response_text FROM [shwetaproject-001:eMee_SMCC.tweets] where not response_text in (\"null\", \"NULL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datalab.bigquery as bq\n",
    "# Create a query using the SQL module defined above.\n",
    "q = bq.Query(logspreview1)\n",
    "# Run the query, with caching turned off (for sample purposes only), so we're sure to be\n",
    "# able to retrieve metadata, such as bytes processed from the resulting query job.\n",
    "results = q.results()\n",
    "list1=list(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    " \n",
    "emoticons_str = r\"\"\"\n",
    "    (?:\n",
    "        [:=;] # Eyes\n",
    "        [oO\\-]? # Nose (optional)\n",
    "        [D\\)\\]\\(\\]/\\\\OpP] # Mouth\n",
    "    )\"\"\"\n",
    " \n",
    "regex_str = [\n",
    "    emoticons_str,\n",
    "    r'<[^>]+>', # HTML tags\n",
    "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
    " \n",
    "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # numbers\n",
    "    r\"(?:[a-z][a-z'\\-_]+[a-z])\", # words with - and '\n",
    "    r'(?:[\\w_]+)', # other words\n",
    "    r'(?:\\S)' # anything else\n",
    "]\n",
    "    \n",
    "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
    "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE)\n",
    " \n",
    "def tokenize(s):\n",
    "    return tokens_re.findall(s)\n",
    " \n",
    "def preprocess(s, lowercase=False):\n",
    "    tokens = tokenize(s)\n",
    "    if lowercase:\n",
    "        tokens = [token if emoticon_re.search(token) else token.lower() for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "tweets=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((u'SonySIX', u'Ans'), 6), ((u'Ans', u'7'), 5), ((u'7', u'ACTING'), 3), ((u'SINGING', u'TNAWeekendTakeover'), 3), ((u'MODELLING', u'amp'), 3)]\n"
     ]
    }
   ],
   "source": [
    "import operator \n",
    "import json\n",
    "from collections import Counter\n",
    "from numpy import *\n",
    " \n",
    "from nltk.corpus import stopwords\n",
    "from nltk import bigrams \n",
    "import string\n",
    " \n",
    "punctuation = list(string.punctuation)\n",
    "stop = stopwords.words('english') + punctuation + ['rt', 'via']\n",
    "\n",
    "count_all = Counter()\n",
    "index=0\n",
    "for d in list1:\n",
    "    # Create a list with all the terms\n",
    "    temp=dict();\n",
    "    tweet = [term for term in preprocess(d['response_text']) \n",
    "              if term not in stop ] \n",
    "    # Update the counter\n",
    "    terms_bigram = bigrams(tweet)\n",
    "    #print terms_bigram\n",
    "    temp['tweet']=tweet\n",
    "    temp['index']=index\n",
    "    index=index+1\n",
    "    #print temp\n",
    "    tweets.append(temp)\n",
    "    count_all.update(terms_bigram)\n",
    "    # Print the first 5 most frequent words\n",
    "    #print \n",
    "keys=['sabtv','BBCEarth','SonyTV','SonyPIX','SonySIX']\n",
    "print(count_all.most_common(5))\n",
    "#for k in tweets:\n",
    "  #print k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "num_vectors = 1000\n",
    "num_clusters = 2\n",
    "num_steps = 100\n",
    "\n",
    "vector_values = []\n",
    "for i in tweets:\n",
    "  vector_values.append([i['tweet'],i['tweet'].count(keys[0]),i['tweet'].count(keys[1]),i['tweet'].count(keys[2]),i['tweet'].count(keys[3]),i['tweet'].count(keys[4]),i['index']])\n",
    "#print vector_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calculating centroids 5\n",
    "centroids=[]\n",
    "i=1\n",
    "while i<6:\n",
    "  for j in vector_values:\n",
    "    if j[i]==1:\n",
    "      centroids.append(j)\n",
    "      #print j\n",
    "      break\n",
    "  i=i+1\n",
    "#print centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 1 :subtv\n",
      ".@sabtv Woah they are Looking super mind-blowing #SABKiDiwaliExclusives\n",
      "@sabtv one is ekmev secretary Bhide other one I cant get #SABKiDiwaliExclusives\n",
      "Looking forward to watching this show - #DilDekeDekhoOnSAB @sabtv  https://t.co/HbbvhL7ubI\n",
      "@pritambakshi501 this show will start from 18 October at night 10pm @sabtv #DilDekeDekhoOnSAB\n",
      "#DilDekeDekhoOnSAB teaser is really superb. Watching it on loop @sabtv https://t.co/TVM2muHNao\n",
      "@sabtv Their JODI looks so cool onstage. Love this couple of Jetha and Daya. #SABKiDiwaliExclusives @sabtv\n",
      "Dil Deke Dekho Press Conference talks animatedly at Press Conference #DilDekeDekhoOnSAB https://t.co/xMXjGggFrt\n",
      "The show will make you wordless to praise it kyunki umar nahin dekhte jab ho jaata hai pyaar! #DilDekeDekhoOnSAB @sabtv\n",
      "#DilDekeDekhoOnSABBuddies The Stage is all Set for  Press Conference!Waiting for more details from @sabtv  https://t.co/8iIFHYFbYz\n",
      "The star cast of #DilDekeDekhoOnSAB are interacting with the media at the grand press conference for the show in Bhâ€¦ https://t.co/hnYC49isFN\n",
      "\n",
      "cluster 2 :BBCEarth\n",
      "@BBCSpringwatch @BBCEarth @BBCiWonder perfect! Thanks guys!!\n",
      "@BBCEarth Chinese are enemy of Humanity and environment. They support terrorist and killing innocent animal.\n",
      "\n",
      "cluster 3 :SonyTV\n",
      "@SonyTV @KushalT2803 @jenwinget @aneri_vajani brilliantttt??????\n",
      "@SonyTV Promote it as much as u wnt..Vil see u shutting tis down soon!!\n",
      "@AashuLoveNISHAL @KushalT2803 @preeti_simoes @SonyTV yup Arjun Sharma nice name :)))..\n",
      "Is @KapilSharmaK9  magic rubbing off on @SonyTV ? https://t.co/jIdq70QI4w @anitarox1111 @TheKapilSShow\n",
      "@Kritika_Kamra @KushalT2803 @jenwinget @SonyTV its not fair  I want to see you on this Prime time of Sony TV. Why you dont think so?\n",
      "\n",
      "cluster 4 :SonyPIX\n",
      "@SonyPIX Ans4 - B) Professor#TheJurassicQuiz\n",
      "@SonyPIX i missed this one! #TheJurassicQuiz\n",
      "#TheJurassicQuiz A) John Hammond was the CEO and Founder!The Jurassic Quiz @SonyPIX\n",
      "\n",
      "cluster 5 :SonySIX\n",
      "@SonySIX yeah #TNAWeekendTakeover\n",
      "@SonySIX A6. Allen Neal Jones #TNAWeekendTakeover\n",
      "@SonySIX A5. Brooke Nichole Adams #TNAWeekendTakeover\n",
      "@SonySIX A4. Nuufolau Joel \"Joe\" Seanoa #TNAWeekendTakeover\n",
      "@SonySIX Ans 2) Author Actor and Bodybuilder#TNAWeekendTakeover\n",
      "@SonySIX Ans7- Acting Modelling And Singing! #TNAWeekendTakeover\n",
      "@SonySIX Ans 7) ACTING MODELLING &amp; SINGING#TNAWeekendTakeover\n",
      "@SonySIX Ans 7) ACTING MODELLING &amp; SINGING#TNAWeekendTakeover\n",
      "@SonySIX Ans 7) ACTING MODELLING &amp; SINGING#TNAWeekendTakeover\n",
      "@SonySIX Ans7- Acting Modelling And Singing.. #TNAWeekendTakeover\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "clusters=[]\n",
    "clusters.append([])\n",
    "clusters.append([])\n",
    "clusters.append([])\n",
    "clusters.append([])\n",
    "clusters.append([])\n",
    "sess=tf.Session()\n",
    "for d in vector_values:\n",
    "  x=[]\n",
    "  #x.append(d[0])\n",
    "  for j in centroids:\n",
    "    u1 = tf.constant(float(d[1]), name='u1')\n",
    "    v1 = tf.constant(float(d[2]), name='v1')\n",
    "    w1 = tf.constant(float(d[3]), name='w1')\n",
    "    x1 = tf.constant(float(d[4]), name='x1')\n",
    "    y1 = tf.constant(float(d[5]), name='y1')\n",
    "    u2 = tf.constant(float(j[1]), name='u2')\n",
    "    v2 = tf.constant(float(j[2]), name='v2')\n",
    "    w2 = tf.constant(float(j[3]), name='w2')\n",
    "    x2 = tf.constant(float(j[4]), name='x2')\n",
    "    y2 = tf.constant(float(j[5]), name='y2')\n",
    "    model = tf.initialize_all_variables()\n",
    "    with sess.as_default():\n",
    "      x.append(tf.sqrt(tf.pow(tf.sub(u1,u2),2)+tf.pow(tf.sub(v1,v2),2)+tf.pow(tf.sub(w1,w2),2)+tf.pow(tf.sub(x1,x2),2)+tf.pow(tf.sub(y1,y2),2)).eval())\n",
    "  clusters[x.index(min(x))].append(list1[d[6]]['response_text'])\n",
    "print \"cluster 1 :subtv\"\n",
    "for k in clusters[0]:\n",
    "  print k\n",
    "print \"\\ncluster 2 :BBCEarth\"\n",
    "for k in clusters[1]:\n",
    "  print k\n",
    "print \"\\ncluster 3 :SonyTV\"\n",
    "for k in clusters[2]:\n",
    "  print k\n",
    "print \"\\ncluster 4 :SonyPIX\"\n",
    "for k in clusters[3]:\n",
    "  print k\n",
    "print \"\\ncluster 5 :SonySIX\"\n",
    "for k in clusters[4]:\n",
    "  print k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
